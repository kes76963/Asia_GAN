{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "#input data 전처리\r\n",
    "from konlpy.tag import Kkma\r\n",
    "kkma = Kkma()\r\n",
    "input_text = '스마트폰'\r\n",
    "input_sim = 50  # input data 유사성 민감도 지정 / 숫자가 작을수록 관련 없는게 나올 확률이 커짐 / 최소 50이상 설정\r\n",
    "input_text_list = input_text.split(' ') # input data 띄어쓰기로 나누기\r\n",
    "noun_list = kkma.nouns(input_text)\r\n",
    "\r\n",
    "# kkma로 명사 추출시 input_text 중복해서 들어가기 때문에 제거\r\n",
    "if len(input_text_list) == len(noun_list) :\r\n",
    "    text = input_text\r\n",
    "\r\n",
    "else :\r\n",
    "    [i for i in input_text_list if not i in noun_list or noun_list.remove(i)] #차집합인데 순서가 안 바뀜 \r\n",
    "    text = ' '.join(noun_list)\r\n",
    "print(text)\r\n",
    "\r\n",
    "#Kkma 처음에 불러오는데 10초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "스마트 폰\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "#슬로건 생성 모델 실행\r\n",
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "\r\n",
    "r = requests.post(\r\n",
    "    'https://train-8dgtlge21881yafjrqb4-gpt2-train-teachable-ainize.endpoint.ainize.ai/predictions/gpt-2-ko-small-finetune', #슬로건 , 없는 정제된 5에포크\r\n",
    "    headers = {'Content-Type' : 'application/json'\r\n",
    "               },\r\n",
    "    data=json.dumps({\r\n",
    "  \"text\": text,\r\n",
    "  \"num_samples\": 50,\r\n",
    "  \"length\": 20\r\n",
    "    }))\r\n",
    "\r\n",
    "#슬로건 추가\r\n",
    "slogan_list = []\r\n",
    "for slogan in r.json():\r\n",
    "    slogan = slogan.split('\\n')[0]\r\n",
    "    slogan = slogan.split(',')[1:]\r\n",
    "    slogan = ', '.join(slogan)\r\n",
    "    if slogan :\r\n",
    "      slogan_list.append(slogan)\r\n",
    "      print(slogan)\r\n",
    "print(len(slogan_list),'개 완료')\r\n",
    "\r\n",
    "#슬로건 데이터 200개 생성 25초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 개 완료\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "#차집합 함수\r\n",
    "def differ_sets(a,b) : \r\n",
    "    lst = list(set(a) - set(b))\r\n",
    "    return lst\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "#영어 슬로건 따로 추출\r\n",
    "import re\r\n",
    "\r\n",
    "eng_list = []\r\n",
    "for slogan in slogan_list :\r\n",
    "    slogan_ = re.sub('[^A-Za-z가-힣]', '',slogan) #영어 한글만 남기기\r\n",
    "    slogan_ = re.sub('[^가-힣]',' ', slogan_) #한글이 있으면 공백 채우기\r\n",
    "    if slogan_.isspace():    #isalpha()는 영어 또는 한글 유무를 찾아서 안 됨\r\n",
    "        eng_list.append(slogan)\r\n",
    "        \r\n",
    "print(eng_list)\r\n",
    "\r\n",
    "#차집합 \r\n",
    "kor_list = differ_sets(slogan_list, eng_list) #한국 슬로건만 있는 리스트"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Good break', 'Imagine possible', 'Go Go', 'The New Original Software', \"What's Pick\", 'Shift Delay on a spring', ' Tour seven', \"It's Digital Success\"]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#영어로는 유사도 분석이 힘들다.\r\n",
    "\r\n",
    "# from sentence_transformers import SentenceTransformer, util\r\n",
    "# import numpy as np\r\n",
    "# import random\r\n",
    "\r\n",
    "# #모델 불러오기\r\n",
    "# model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "# #유사도 비교할 리스트\r\n",
    "# corpus = eng_list\r\n",
    "# corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "# #비교할 슬로건 선택 => 임시로 우선 정해서 정확도 확인\r\n",
    "# queries = random.sample(eng_list, 3)\r\n",
    "\r\n",
    "# top_k = 4\r\n",
    "# for query in queries:\r\n",
    "#     query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "#     cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "#     cos_scores = cos_scores.cpu()\r\n",
    "\r\n",
    "#     #We use np.argpartition, to only partially sort the top_k results\r\n",
    "#     top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] \r\n",
    "\r\n",
    "#     print(\"\\n======================\\n\")\r\n",
    "#     print(\"Query:\", query)\r\n",
    "#     print(\"\\nTop 5 most similar sentences in corpus:\")\r\n",
    "\r\n",
    "#     for idx in top_results[1:top_k]:\r\n",
    "#         print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======================\n",
      "\n",
      "Query: I MAPPEED SUPER TOME\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "THE BATTY BEAD STIGHT T (Score: 0.6062)\n",
      "THE BEAUTY MAKE S (Score: 0.5947)\n",
      "KBLEITAL ME TOUR MY TH (Score: 0.5820)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: WHAT YOUR MAKE\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "WEEK YOUR BUTIONAR O (Score: 0.6320)\n",
      "THE BEAUTY MAKE S (Score: 0.5894)\n",
      "MY CALLE (Score: 0.5767)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: We lovers that wear. all. Mind for m\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "I MAKE YOUR MILK,  CHARE (Score: 0.3331)\n",
      "WE PRISME A COLLECTION (Score: 0.2203)\n",
      "I MAPPEED SUPER TOME (Score: 0.2047)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "#문장 유사도\r\n",
    "#개별 추출\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "#모델 불러오기\r\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "#유사도 비교할 리스트\r\n",
    "corpus = kor_list\r\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "\r\n",
    "#비교할 슬로건 선택 \r\n",
    "no_sim_list = [] #관련 없는 슬로건 추출\r\n",
    "n = 0\r\n",
    "try : #n이 증가하지 않을 경우 무한루프? \r\n",
    "    while n < 5 :\r\n",
    "        query = random.sample(kor_list, 1)\r\n",
    "        print('='*40)\r\n",
    "        print(\"Query : \", query)\r\n",
    "        kor_list = differ_sets(kor_list, query)  #kor_list에서 query를 제거 \r\n",
    "        \r\n",
    "        #코사인 유사도 사용하여 5개 유사한 슬로건 찾기\r\n",
    "        top_k = 6 #query 포함 top 5개\r\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "        cos_scores = cos_scores.cpu()\r\n",
    "        top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] # np 사용 이유 : 순위를 순서대로 맞추기 위함\r\n",
    "        \r\n",
    "        #민감도 비교하기 위한 유사도 더하기      \r\n",
    "        sum = 0\r\n",
    "        for idx in top_results[1:top_k]:\r\n",
    "            sum += cos_scores[idx]\r\n",
    "        f_sum = float(sum)/5 #tensor to float\r\n",
    "        print(f_sum)\r\n",
    "        \r\n",
    "        #사용자 인풋 민감도 비교    \r\n",
    "        sim_list = [] #유사 슬로건 담을 리스트\r\n",
    "        if f_sum >= input_sim / 100 :\r\n",
    "            for idx in top_results[0:top_k-1]:\r\n",
    "                sim_list.append(corpus[idx].strip())\r\n",
    "            print(sim_list)\r\n",
    "            kor_list = differ_sets(kor_list, sim_list)\r\n",
    "            n += 1\r\n",
    "            #print(len(kor_list))\r\n",
    "            \r\n",
    "        else : \r\n",
    "            no_sim_list.append(query)\r\n",
    "            print('관련이 없는 슬로건 데이터 추가')\r\n",
    "  \r\n",
    "                \r\n",
    "                \r\n",
    "except :\r\n",
    "    print('데이터가 부족합니다.')\r\n",
    "    \r\n",
    "print('완료')\r\n",
    "print(no_sim_list)\r\n",
    "\r\n",
    "#슬로건 25개 보여주는데 40초 / 모델 불러들어오는 시간 포함 => 다시 시작되면 2~5초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\n",
      "Query :  ['이제 피부가 깨끗해졌습니다']\n",
      "0.7614649772644043\n",
      "['이제 피부가 깨끗해졌습니다', '이제부터 피부도 피부다', '이제 피부가 알아서 알아서', '이제 피부를 지켜주세요', '오늘의 피부']\n",
      "========================================\n",
      "Query :  ['그것은 아름다움을 만드는 시간입니다']\n",
      "0.6298552989959717\n",
      "['그것은 아름다움을 만드는 시간입니다', '당신의 모든 순간이 아름답습니다', '모든 순간을 아름답게', '당신은 지금 이 순간에도 뷰티스타일', '아름답게 예뻐지자']\n",
      "========================================\n",
      "Query :  ['수고했다,  나만의 스타일리스트']\n",
      "0.45457162857055666\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "========================================\n",
      "Query :  ['나를 사랑하는 아름다움']\n",
      "0.7339666843414306\n",
      "['나를 사랑하는 아름다움', '나는 아름답다', '아름답게 예뻐지자', '당신만의 아름다움', '나는 당신의 아름다움에 감탄한다']\n",
      "========================================\n",
      "Query :  ['나만의 화장실을 꾸립니다']\n",
      "0.39769206047058103\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "========================================\n",
      "Query :  ['화장품 브랜드,  립케어']\n",
      "0.4849266052246094\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "========================================\n",
      "Query :  ['대한민국 1등']\n",
      "0.6913610458374023\n",
      "['대한민국 1등', '대한민국 NO.1 TSG피부', '대한민국 No.1 안티에이징', '대한민국 No.1 수분 밸런스', '대한민국 NO.1 뷰티브랜드']\n",
      "========================================\n",
      "Query :  ['화사한 피부를 위하여']\n",
      "0.7406060218811035\n",
      "['화사한 피부를 위하여', '미세먼지로부터 피부를 지켜주는', '피부엔 스킨케어가 필요할 때', '피부 보습이 필요한 순간', '이제부터 피부도 피부다']\n",
      "완료\n",
      "[['수고했다,  나만의 스타일리스트'], ['나만의 화장실을 꾸립니다'], ['화장품 브랜드,  립케어']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#문장 유사도\r\n",
    "#개별 추출\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "#모델 불러오기\r\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "#유사도 비교할 리스트\r\n",
    "corpus = kor_list\r\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "\r\n",
    "#비교할 슬로건 선택 \r\n",
    "confirm_list = [] # 슬로건 추출\r\n",
    "n = 0\r\n",
    "try : #n이 증가하지 않을 경우 무한루프? \r\n",
    "    while n < 10 :\r\n",
    "        query = random.sample(kor_list, 1)\r\n",
    "        # print('='*40)\r\n",
    "        # print(\"Query : \", query)\r\n",
    "        kor_list = differ_sets(kor_list, query)  #kor_list에서 query를 제거 \r\n",
    "        \r\n",
    "        #코사인 유사도 사용하여 5개 유사한 슬로건 찾기\r\n",
    "        top_k = 6 #query 포함 top 5개\r\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "        cos_scores = cos_scores.cpu()\r\n",
    "        top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] # np 사용 이유 : 순위를 순서대로 맞추기 위함\r\n",
    "        \r\n",
    "        #민감도 비교하기 위한 유사도 더하기      \r\n",
    "        sum = 0\r\n",
    "        for idx in top_results[1:top_k]:\r\n",
    "            sum += cos_scores[idx]\r\n",
    "        f_sum = float(sum)/5 #tensor to float\r\n",
    "        # print(f_sum)\r\n",
    "        \r\n",
    "        #사용자 인풋 민감도 비교    \r\n",
    "        if f_sum >= input_sim / 100 :\r\n",
    "            confirm_list.append(query)\r\n",
    "            n += 1\r\n",
    "            #print(len(kor_list))\r\n",
    "            \r\n",
    "        else : \r\n",
    "            no_sim_list.append(query)\r\n",
    "            print('관련이 없는 슬로건 데이터 추가')\r\n",
    "  \r\n",
    "                \r\n",
    "                \r\n",
    "except :\r\n",
    "    print('데이터가 부족합니다.')\r\n",
    "    \r\n",
    "print('완료')\r\n",
    "print(confirm_list)\r\n",
    "\r\n",
    "#슬로건 25개 보여주는데 40초 / 모델 불러들어오는 시간 포함 => 다시 시작되면 2~5초"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}